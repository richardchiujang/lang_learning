import os
import json
import whisper
import ffmpeg
import yt_dlp
import google.generativeai as genai
import shutil
from datetime import timedelta

# --- å…¨åŸŸè¨­å®š ---
# âš ï¸âš ï¸âš ï¸ è«‹åœ¨æ­¤å¡«å…¥æ‚¨çš„ Google Gemini API Key âš ï¸âš ï¸âš ï¸
GEMINI_API_KEY = "æ‚¨çš„_GOOGLE_GEMINI_API_KEY" 

OUTPUT_DIR = "./app_assets"
TEMP_DIR = "./temp_downloads"

# å»ºç«‹å¿…è¦çš„è³‡æ–™å¤¾
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(TEMP_DIR, exist_ok=True)

# è¨­å®š Gemini
if "æ‚¨çš„_GOOGLE" not in GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

class YouTubeContentFactory:
    def __init__(self, model_size="base", batch_size=15):
        print(f"ğŸ“¡ æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹ ({model_size})...")
        self.model = whisper.load_model(model_size)
        
        # æ”¹ç”¨ Gemini 2.0 Flash Lite
        self.model_name = 'gemini-2.5-flash'
        print(f"ğŸ§  è¨­å®š AI æ¨¡å‹ç‚º: {self.model_name}")
        self.gemini_model = genai.GenerativeModel(self.model_name)
        
        # æ‰¹æ¬¡è™•ç†å¤§å°ï¼ˆé¿å…å–®æ¬¡è«‹æ±‚éé•·ï¼‰
        self.batch_size = batch_size
        print(f"   æ‰¹æ¬¡è™•ç†å¤§å°: {batch_size} å€‹ç‰‡æ®µ/æ¬¡")
        print(f"   ğŸ’¡ ç­–ç•¥: Gemini ç¿»è­¯ + Whisper words é™£åˆ—ï¼ˆç”¨æ–¼è‹±æ–‡é€å­—é«˜äº®ï¼‰")

    # --- ğŸ†• æ–°å¢æ–¹æ³•ï¼šåªå–å¾— ID ä¸ä¸‹è¼‰å½±ç‰‡ ---
    def _get_video_id(self, url):
        """å¿«é€Ÿå–å¾—å½±ç‰‡ ID ä»¥ä¾¿æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨"""
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'skip_download': True, # é—œéµï¼šè¨­å®šç‚º True è¡¨ç¤ºåªæŠ“è³‡è¨Šä¸ä¸‹è¼‰æª”æ¡ˆ
            'nocheckcertificate': True,  # è·³é SSL æ†‘è­‰é©—è­‰
            'no_check_certificate': True,  # å‚™ç”¨é¸é …
        }
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                return info.get('id')
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•å–å¾—å½±ç‰‡ ID: {e}")
            return None

    def process_url(self, youtube_url):
        print(f"\nğŸš€ æº–å‚™è™•ç†: {youtube_url}")
        
        # --- 1. å„ªå…ˆæª¢æŸ¥ï¼šæª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨ï¼Ÿ ---
        # å…ˆå¿«é€Ÿå–å¾— ID (ä¸ä¸‹è¼‰å½±ç‰‡)
        video_id = self._get_video_id(youtube_url)
        
        if not video_id:
            print("âŒ ç„¡æ³•å–å¾—å½±ç‰‡ IDï¼Œè·³éæ­¤é€£çµã€‚")
            return

        # æª¢æŸ¥ç›®æ¨™ JSON æ˜¯å¦å·²ç¶“åœ¨è³‡æ–™å¤¾ä¸­
        expected_json_path = os.path.join(OUTPUT_DIR, f"{video_id}.json")
        
        if os.path.exists(expected_json_path):
            # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ç¿»è­¯ï¼ˆæª”æ¡ˆå­˜åœ¨ä½†ç„¡ä¸­æ–‡ç¿»è­¯ï¼‰
            try:
                with open(expected_json_path, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                
                # æª¢æŸ¥ segments ä¸­æ˜¯å¦æœ‰ "[ç„¡ä¸­æ–‡ç¿»è­¯]"
                segments = existing_data.get("segments", [])
                needs_translation = any(
                    seg.get("text_zh") == "[ç„¡ä¸­æ–‡ç¿»è­¯]" for seg in segments
                )
                
                if needs_translation:
                    print(f"ğŸ”„ æª”æ¡ˆå·²å­˜åœ¨ä½†ç¼ºå°‘ä¸­æ–‡ç¿»è­¯ï¼Œé–‹å§‹é‡æ–°ç¿»è­¯...")
                    # æå–åŸå§‹ segments é€²è¡Œ Gemini ç¿»è­¯
                    self._retranslate_existing_json(expected_json_path, existing_data)
                    return
                else:
                    print(f"â­ï¸  æª”æ¡ˆå·²å­˜åœ¨ä¸”å·²å®Œæˆç¿»è­¯ ({video_id}.json)ï¼Œè·³éè™•ç†ã€‚")
                    return
            except Exception as e:
                print(f"âš ï¸ è®€å–ç¾æœ‰æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                print(f"   å°‡è·³éæ­¤æª”æ¡ˆï¼Œç¹¼çºŒä¸‹ä¸€å€‹ã€‚")
                return
        # -------------------------------------

        print(f"ğŸ“¥ æª”æ¡ˆä¸å­˜åœ¨ï¼Œé–‹å§‹ä¸‹è¼‰å½±ç‰‡...")

        # 2. ä¸‹è¼‰å½±ç‰‡
        video_info = self._download_youtube_video(youtube_url)
        if not video_info: 
            print("âŒ å½±ç‰‡ä¸‹è¼‰å¤±æ•—ï¼Œä¸­æ­¢è™•ç†ã€‚")
            return

        video_path = video_info['path']
        video_title = video_info['title']
        
        # 3. è½‰éŒ„ (Whisper)
        audio_path = os.path.join(TEMP_DIR, f"{video_id}.wav")
        self._extract_audio(video_path, audio_path)
        
        if not os.path.exists(audio_path):
            print("âŒ éŸ³è¨Šæå–å¤±æ•—ï¼Œè«‹æª¢æŸ¥é›»è…¦æ˜¯å¦å·²å®‰è£ FFmpegã€‚")
            return

        print("ğŸ¤– æ­£åœ¨é€²è¡Œ Whisper èªéŸ³è¾¨è­˜ (å°‡éŸ³è¨Šè½‰ç‚ºæ–‡å­—)...")
        result = self.model.transcribe(audio_path, fp16=False, word_timestamps=True)
        raw_segments = result["segments"]

        # 4. Gemini èªæ„è™•ç†ï¼ˆæ”¯æ´æ‰¹æ¬¡è™•ç†ï¼‰
        print("ğŸ§  æ­£åœ¨å‘¼å« Gemini é€²è¡Œèªæ„åˆä½µèˆ‡ç¿»è­¯...")
        processed_segments = self._process_segments_in_batches(raw_segments)

        if not processed_segments:
            print("âš ï¸ Gemini è™•ç†å¤±æ•—ï¼Œå„²å­˜ Whisper åŸå§‹çµæœä»¥ä¾¿ç¨å¾Œé‡æ–°ç¿»è­¯ã€‚")
            # å°‡ Whisper åŸå§‹æ ¼å¼è½‰æ›ç‚ºæ’­æ”¾å™¨å¯è®€å–çš„æ ¼å¼
            processed_segments = [
                {
                    "id": seg.get("id", i),
                    "start_time": seg["start"],
                    "end_time": seg["end"],
                    "text_en": seg["text"].strip(),
                    "text_zh": "[ç„¡ä¸­æ–‡ç¿»è­¯]",  # ç„¡ç¿»è­¯æ™‚é¡¯ç¤ºæç¤º
                    "keywords": [],
                    "words": seg.get("words", [])  # ä¿ç•™ word-level timestamps ä»¥ä¾¿æœªä¾†é‡æ–°è™•ç†
                }
                for i, seg in enumerate(raw_segments)
            ]
            self._list_available_models()
            
            # ç›´æ¥å„²å­˜ JSON ä¸¦çµæŸè™•ç†
            self._save_json_and_files(video_id, video_title, youtube_url, video_path, 
                                     video_info, processed_segments)
            return

        # 5. Gemini æˆåŠŸï¼Œç¹¼çºŒæ­£å¸¸è™•ç†
        self._save_json_and_files(video_id, video_title, youtube_url, video_path, 
                                 video_info, processed_segments)

    def _save_json_and_files(self, video_id, video_title, youtube_url, video_path, 
                            video_info, processed_segments):
        """å„²å­˜ JSON å’Œç›¸é—œæª”æ¡ˆçš„å…±ç”¨æ–¹æ³•"""
        print("ğŸµ æ­£åœ¨æå– MP3 éŸ³è¨Šæª”...")
        mp3_filename = f"{video_id}.mp3"
        mp3_path = os.path.join(OUTPUT_DIR, mp3_filename)
        self._extract_audio_mp3(video_path, mp3_path)
        
        # è¨ˆç®—æª”æ¡ˆå¤§å°ï¼ˆå¯é¸ï¼‰
        audio_size_mb = 0
        if os.path.exists(mp3_path):
            audio_size_mb = round(os.path.getsize(mp3_path) / (1024 * 1024), 2)

        # æ‰“åŒ… JSON
        app_data = {
            "lesson_id": video_id,
            "title": video_title,
            "source_url": youtube_url,
            "video_filename": os.path.basename(video_path),
            "audio_filename": mp3_filename,
            "audio_only_size_mb": audio_size_mb,
            "duration": video_info['duration'],
            "segments": processed_segments
        }

        # å­˜æª” JSON
        json_path = os.path.join(OUTPUT_DIR, f"{video_id}.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(app_data, f, ensure_ascii=False, indent=2)
            
        # è¤‡è£½å½±ç‰‡æª”åˆ°è¼¸å‡ºè³‡æ–™å¤¾
        final_video_path = os.path.join(OUTPUT_DIR, os.path.basename(video_path))
        if os.path.exists(video_path):
             shutil.copy2(video_path, final_video_path)
             print(f"   (åŸå§‹å½±ç‰‡å·²ä¿ç•™åœ¨: {video_path})")
        
        print(f"âœ… è™•ç†å®Œæˆï¼\n   ğŸ“„ JSON æª”: {json_path}\n   ğŸ¥ å½±ç‰‡æª”: {final_video_path}\n   ğŸµ éŸ³è¨Šæª”: {mp3_path} ({audio_size_mb} MB)")

    def _process_segments_in_batches(self, raw_segments):
        """å°‡ç‰‡æ®µåˆ†æ‰¹è™•ç†ï¼Œé¿å…å–®æ¬¡è«‹æ±‚éé•·å°è‡´å›æ‡‰è¢«æˆªæ–·"""
        total_segments = len(raw_segments)
        
        # å¦‚æœç‰‡æ®µæ•¸é‡å°‘æ–¼æ‰¹æ¬¡å¤§å°ï¼Œç›´æ¥è™•ç†
        if total_segments <= self.batch_size:
            return self._process_with_gemini(raw_segments)
        
        # åˆ†æ‰¹è™•ç†
        print(f"   ç¸½å…± {total_segments} å€‹ç‰‡æ®µï¼Œå°‡åˆ† {(total_segments + self.batch_size - 1) // self.batch_size} æ‰¹æ¬¡è™•ç†")
        all_processed = []
        
        for i in range(0, total_segments, self.batch_size):
            batch_num = i // self.batch_size + 1
            batch = raw_segments[i:i + self.batch_size]
            print(f"   ğŸ“¦ è™•ç†ç¬¬ {batch_num} æ‰¹ ({len(batch)} å€‹ç‰‡æ®µ)...")
            
            processed_batch = self._process_with_gemini(batch)
            
            if not processed_batch:
                print(f"   âŒ ç¬¬ {batch_num} æ‰¹è™•ç†å¤±æ•—")
                return None
            
            all_processed.extend(processed_batch)
        
        print(f"   âœ… æ‰€æœ‰æ‰¹æ¬¡è™•ç†å®Œæˆï¼Œå…± {len(all_processed)} å€‹ç‰‡æ®µ")
        return all_processed

    def _process_with_gemini(self, raw_segments):
        # ä¸åŒ…å« words é™£åˆ—ç™¼é€çµ¦ Geminiï¼Œé¿å…å›æ‡‰éé•·è¢«æˆªæ–·
        simplified_input = [
            {
                "id": i, 
                "start": seg["start"], 
                "end": seg["end"], 
                "text": seg["text"].strip()
            } 
            for i, seg in enumerate(raw_segments)
        ]

        prompt = f"""
        Translate to Traditional Chinese (Taiwan). Keep exact structure.
        
        Input ({len(simplified_input)} segments):
        {json.dumps(simplified_input, ensure_ascii=False)}

        Output ({len(simplified_input)} segments with translations):
        [
          {{
            "id": <same>,
            "start_time": <same start>,
            "end_time": <same end>,
            "text_en": "<same text>",
            "text_zh": "ä¸­æ–‡ç¿»è­¯",
            "keywords": ["important_word"]
          }}
        ]
        
        Rules:
        - Output EXACTLY {len(simplified_input)} items
        - keywords: choose difficult, important, meaning and name words (min 1,max 5), in English
        - don't translate keywords.
        - Keep all IDs, timestamps, text_en unchanged
        """

        response = None
        try:
            response = self.gemini_model.generate_content(prompt)
            response_text = response.text
            
            # æª¢æŸ¥å›æ‡‰æ˜¯å¦è¢«æˆªæ–·
            if len(response_text) > 100000:
                print(f"   âš ï¸ Gemini å›æ‡‰éé•· ({len(response_text)} å­—å…ƒ)ï¼Œå¯èƒ½è¢«æˆªæ–·")
            
            clean_text = response_text.replace("```json", "").replace("```", "").strip()
            
            # å˜—è©¦è§£æ JSON
            parsed_data = json.loads(clean_text)
            
            # é©—è­‰è¼¸å‡ºç‰‡æ®µæ•¸é‡
            if len(parsed_data) != len(simplified_input):
                print(f"   âš ï¸ è­¦å‘Š: Gemini åˆä½µäº†ç‰‡æ®µï¼è¼¸å…¥ {len(simplified_input)} å€‹ï¼Œè¼¸å‡º {len(parsed_data)} å€‹")
                print(f"   ç‰‡æ®µæ•¸é‡ä¸ç¬¦ï¼Œæ”¾æ£„æ­¤æ‰¹æ¬¡")
                return None
            
            # âœ¨ é—œéµæ­¥é©Ÿï¼šå°‡åŸå§‹ Whisper çš„ words é™£åˆ—åŠ å›å»
            for i, item in enumerate(parsed_data):
                item["words"] = raw_segments[i].get("words", [])
            
            print(f"âœ… Gemini æˆåŠŸè™•ç† {len(parsed_data)} å€‹ç‰‡æ®µ")
            return parsed_data
            
        except json.JSONDecodeError as e:
            print(f"\nâŒ Gemini å›æ‡‰æ ¼å¼éŒ¯èª¤ (ç„¡æ³•è§£æ JSON)")
            print(f"   éŒ¯èª¤è©³æƒ…: {e}")
            if response and hasattr(response, 'text'):
                print(f"   å›æ‡‰é•·åº¦: {len(response.text)} å­—å…ƒ")
            print(f"   è·³éæ­¤æ‰¹æ¬¡ï¼Œç¹¼çºŒè™•ç†ä¸‹ä¸€æ‰¹")
            return None
                
        except Exception as e:
            print(f"\nâŒ Gemini API å‘¼å«å¤±æ•—")
            print(f"   éŒ¯èª¤é¡å‹: {type(e).__name__}")
            print(f"   éŒ¯èª¤è¨Šæ¯: {str(e)}")
            
            # æª¢æŸ¥å¸¸è¦‹éŒ¯èª¤
            error_msg = str(e).lower()
            if 'quota' in error_msg or 'limit' in error_msg:
                print(f"   ğŸ’¡ å¯èƒ½åŸå› : API é…é¡ç”¨å®Œæˆ–é”åˆ°é€Ÿç‡é™åˆ¶")
                print(f"   å»ºè­°: æª¢æŸ¥ https://aistudio.google.com/app/apikey")
            elif 'api_key' in error_msg or 'authentication' in error_msg:
                print(f"   ğŸ’¡ å¯èƒ½åŸå› : API Key ç„¡æ•ˆæˆ–éæœŸ")
            elif 'permission' in error_msg:
                print(f"   ğŸ’¡ å¯èƒ½åŸå› : API Key æ¬Šé™ä¸è¶³")
            elif 'timeout' in error_msg or 'connection' in error_msg:
                print(f"   ğŸ’¡ å¯èƒ½åŸå› : ç¶²è·¯é€£ç·šå•é¡Œ")
            
            return None

    def _retranslate_existing_json(self, json_path, existing_data):
        """é‡æ–°ç¿»è­¯å·²å­˜åœ¨ä½†ç¼ºå°‘ä¸­æ–‡ç¿»è­¯çš„ JSON æª”æ¡ˆ"""
        print("ğŸ§  æ­£åœ¨å‘¼å« Gemini é‡æ–°ç¿»è­¯ç¾æœ‰ç‰‡æ®µ...")
        
        segments = existing_data.get("segments", [])
        
        # æº–å‚™è¼¸å…¥çµ¦ Geminiï¼ˆæ¨¡æ“¬ raw_segments æ ¼å¼ï¼Œä¿ç•™ wordsï¼‰
        raw_segments_format = [
            {
                "start": seg.get("start_time", seg.get("start", 0)),
                "end": seg.get("end_time", seg.get("end", 0)),
                "text": seg.get("text_en", seg.get("text", "")),
                "words": seg.get("words", [])  # ä¿ç•™åŸå§‹ words é™£åˆ—
            }
            for seg in segments
        ]
        
        # ä½¿ç”¨æ‰¹æ¬¡è™•ç†æ–¹æ³•é€²è¡Œç¿»è­¯
        processed_segments = self._process_segments_in_batches(raw_segments_format)
        
        if processed_segments:
            # æ›´æ–° JSON è³‡æ–™
            existing_data["segments"] = processed_segments
            
            # å­˜æª”
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… é‡æ–°ç¿»è­¯å®Œæˆï¼å·²æ›´æ–°æª”æ¡ˆ: {json_path}")
        else:
            print(f"âŒ Gemini ç¿»è­¯å¤±æ•—ï¼Œä¿æŒåŸæª”æ¡ˆä¸è®Šã€‚")

    def _list_available_models(self):
        print("\nğŸ” æ­£åœ¨æŸ¥è©¢æ‚¨å¸³è™Ÿå¯ç”¨çš„æ¨¡å‹åˆ—è¡¨...")
        try:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    print(f" - {m.name}")
        except Exception as e:
            print(f"ç„¡æ³•åˆ—å‡ºæ¨¡å‹: {e}")

    def _download_youtube_video(self, url):
        ydl_opts = {
            'format': 'bestvideo[ext=mp4][height<=720]+bestaudio[ext=m4a]/best[ext=mp4]/best',
            'outtmpl': os.path.join(TEMP_DIR, '%(id)s.%(ext)s'),
            'quiet': True,
            'no_warnings': True,
            'nocheckcertificate': True,
        }
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=True)
                return {
                    'id': info['id'],
                    'title': info['title'],
                    'duration': info['duration'],
                    'path': ydl.prepare_filename(info)
                }
        except Exception as e:
            print(f"ä¸‹è¼‰æ¨¡çµ„éŒ¯èª¤: {e}")
            return None

    def _extract_audio(self, video_path, audio_output_path):
        try:
            (
                ffmpeg
                .input(video_path)
                .output(audio_output_path, acodec='pcm_s16le', ac=1, ar='16k')
                .run(quiet=True, overwrite_output=True)
            )
        except ffmpeg.Error:
            pass

    def _extract_audio_mp3(self, video_path, audio_output_path):
        """æå– MP3 æ ¼å¼éŸ³è¨Šï¼ˆç”¨æ–¼æ‰‹æ©Ÿç‰ˆç´”éŸ³è¨Šæ¨¡å¼ï¼‰"""
        try:
            (
                ffmpeg
                .input(video_path)
                .output(audio_output_path, 
                       acodec='libmp3lame', 
                       audio_bitrate='128k',
                       ac=2)  # ç«‹é«”è²
                .run(quiet=True, overwrite_output=True)
            )
            print(f"   âœ… MP3 éŸ³è¨Šæª”å·²ç”Ÿæˆ")
        except ffmpeg.Error as e:
            print(f"   âš ï¸ MP3 æå–å¤±æ•—: {e}")

# --- åŸ·è¡Œå€ ---
if __name__ == "__main__":
    if "æ‚¨çš„_GOOGLE" in GEMINI_API_KEY:
        print("âŒ éŒ¯èª¤ï¼šè«‹å…ˆåœ¨ç¨‹å¼ç¢¼ç¬¬ 11 è¡Œå¡«å…¥æ‚¨çš„ Google Gemini API Key")
    else:
        factory = YouTubeContentFactory(model_size="base")
        
        # æ‚¨å¯ä»¥åœ¨é€™è£¡æ”¾å…¥å¤§é‡çš„ç¶²å€ï¼Œå·²ä¸‹è¼‰éçš„æœƒè‡ªå‹•è·³é
        video_urls = [
            "https://www.youtube.com/watch?v=X0W6CX-uHhk",
            "https://www.youtube.com/watch?v=UF8uR6Z6KLc",
            "https://www.youtube.com/watch?v=zG3gbdb00lY&list=PPSV",
            "https://www.youtube.com/watch?v=D6SHe459EPM",
            "https://www.youtube.com/watch?v=gaMPn1doLac",
            "https://www.youtube.com/watch?v=jNI0fiX4q4A",
            "https://www.youtube.com/watch?v=NsyI9LIXbFM",
            "https://www.youtube.com/watch?v=xjycSL8JJUI",
        ]
        
        for url in video_urls:
            factory.process_url(url)